{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# ST-GAT Traffic Speed Prediction with Partial Sensor Network\n",
        "by Da Lei"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxG3DeP7HVLn"
      },
      "source": [
        "We will walk through the following steps: \n",
        "1.   Installation and Setup\n",
        "2.   Creating a dataloader\n",
        "3.   Building the Model\n",
        "4.   Creating train and evaluation functions\n",
        "5.   Train the model\n",
        "6.   Test the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWfDhJudfxv0",
        "outputId": "248e2c07-238a-4b6c-9843-f85122998334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 793 kB 35.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 34.1 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq ipdb\n",
        "import ipdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "We recommend using a GPU for running our project.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OraOHb9w5-o_",
        "outputId": "dc47aa25-344e-40ee-9c84-109266d0666d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu\n",
            "1.12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x207Q4T_C_w7"
      },
      "source": [
        "Install PyTorch, PyG, and other necessary python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "573fff6e-23fd-495c-947d-81f7e949eeff"
      },
      "outputs": [],
      "source": [
        "# Install torch geometric\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7A5EQM6VEU"
      },
      "source": [
        "Mount google for output directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "b256e095-e9da-4cd1-9809-4a64a06b2803"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'git' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd '/content/'\n",
        "!git clone https://github.com/jswang/stgat_traffic_prediction.git\n",
        "# %cd stgat_traffic_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBeDJoKk8J3s"
      },
      "outputs": [],
      "source": [
        "%cd stgat_traffic_prediction # cd afer delete utils folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive D is New Volume\n",
            " Volume Serial Number is E21E-AA53\n",
            "\n",
            " Directory of d:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\n",
            "\n",
            "2022/09/04  17:49    <DIR>          .\n",
            "2022/09/02  15:44    <DIR>          ..\n",
            "2022/09/02  19:23    <DIR>          __pycache__\n",
            "2022/09/02  15:46         1,343,123 00_DataPreprocessing.ipynb\n",
            "2022/09/04  17:48            43,006 01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_(Kowlong).ipynb\n",
            "2022/09/04  17:54            90,786 02_LA_case.ipynb\n",
            "2022/09/04  17:53    <DIR>          dataset\n",
            "2022/05/16  21:58             1,440 feature_propagation.py\n",
            "2022/05/16  21:58             2,379 filling_strategies.py\n",
            "2022/09/04  17:27    <DIR>          processed\n",
            "2022/09/04  17:40    <DIR>          raw\n",
            "2022/05/16  21:58             1,913 utils.py\n",
            "               6 File(s)      1,482,647 bytes\n",
            "               6 Dir(s)  1,484,652,904,448 bytes free\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqOWp_S591MB"
      },
      "source": [
        "## Creating a Dataloader\n",
        "Now, we create a dataloader which will process data from `.csv` files into a PyTorch Geometric dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TEKy_v5EFPMt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from shutil import copyfile\n",
        "from filling_strategies import filling\n",
        "from utils import get_missing_feature_mask\n",
        "\n",
        "# ipdb.set_trace()\n",
        "\n",
        "def distance_to_weight(W, sigma2=0.1, epsilon=0.5, gat_version=False):\n",
        "    \"\"\"\"\n",
        "    Given distances between all nodes, convert into a weight matrix\n",
        "    :param W distances\n",
        "    :param sigma2 User configurable parameter to adjust sparsity of matrix\n",
        "    :param epsilon User configurable parameter to adjust sparsity of matrix\n",
        "    :param gat_version If true, use 0/1 weights with self loops. Otherwise, use float\n",
        "    \"\"\"\n",
        "    n = W.shape[0]\n",
        "    W = W / 10000.\n",
        "    W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
        "    # refer to Eq.10\n",
        "    W = np.exp(-W2 / sigma2) * (np.exp(-W2 / sigma2) >= epsilon) * W_mask\n",
        "\n",
        "    # If using the gat version of this, round to 0/1 and include self loops\n",
        "    if gat_version:\n",
        "      W[W>0] = 1\n",
        "      W += np.identity(n)\n",
        "\n",
        "    return W\n",
        "\n",
        "class TrafficDataset(InMemoryDataset):\n",
        "    \"\"\"\n",
        "    Dataset for Graph Neural Networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, W, root='', transform=None, pre_transform=None):\n",
        "        self.config = config\n",
        "        self.W = W\n",
        "        # ipdb.set_trace()\n",
        "        super().__init__(root, transform, pre_transform) # would call __init__ of Class InMemoryDataset\n",
        "        self.data, self.slices, self.n_node, self.mean, self.std_dev = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [os.path.join(self.raw_dir, 'PeMSD7_V_228.csv')]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['./data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        copyfile('./dataset/PeMSD7_V_228.csv', os.path.join(self.raw_dir, 'PeMSD7_V_228.csv'))\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"\n",
        "        Process the raw datasets into saved .pt dataset for later use.\n",
        "        Note that any self.fields here wont exist if loading straight from the .pt file\n",
        "        \"\"\"\n",
        "        # Data Preprocessing and loading\n",
        "        # ipdb.set_trace()\n",
        "        data = pd.read_csv(self.raw_file_names[0], header=None).values\n",
        "\n",
        "        # Technically using the validation and test datasets here, but it's fine, would normally get the\n",
        "        # mean and std_dev from a large dataset\n",
        "        mean =  np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "        data = z_score(data, np.mean(data), np.std(data))\n",
        "\n",
        "        _, n_node = data.shape\n",
        "        n_window = self.config['N_PRED'] + self.config['N_HIST']\n",
        "\n",
        "        edge_index_ls_o = []\n",
        "        edge_index_ls_d = []\n",
        "        edge_attr = []\n",
        "        for i in range(n_node):\n",
        "          for j in range(n_node):\n",
        "            if self.W[i,j] != 0:\n",
        "              edge_index_ls_o.append(i)\n",
        "              edge_index_ls_d.append(j)\n",
        "              edge_attr.append(self.W[i,j])\n",
        "        edge_index = torch.tensor([edge_index_ls_o, edge_index_ls_d], dtype=torch.long)\n",
        "        edge_attr = torch.tensor(edge_attr).resize_(edge_index.shape[1], 1)\n",
        "\n",
        "        # another faster version for: adj matrix to edge_index\n",
        "        # adj_t = torch.tensor([[0,1,0,0],[1,0,0,0], [1,0,0,1], [0,0,1,0]])\n",
        "        # edge_index = adj_t.nonzero().t().contiguous()\n",
        "\n",
        "        # >>> tensor([[0, 1, 2, 2, 3],\n",
        "        #             [1, 0, 0, 3, 2]])\n",
        "\n",
        "        # # Below is the original version for generating edge_index and edge_attr \n",
        "        # # manipulate nxn matrix into 2xnum_edges\n",
        "        # edge_index = torch.zeros((2, n_node**2), dtype=torch.long)\n",
        "        # # create an edge_attr matrix with our weights  (num_edges x 1) --> our edge features are dim 1\n",
        "        # edge_attr = torch.zeros((n_node**2, 1))\n",
        "        # num_edges = 0\n",
        "        # for i in range(n_node):\n",
        "        #     for j in range(n_node):\n",
        "        #         if self.W[i, j] != 0.:\n",
        "        #             edge_index[0, num_edges] = i\n",
        "        #             edge_index[1, num_edges] = j\n",
        "        #             edge_attr[num_edges] = self.W[i, j]\n",
        "        #             num_edges += 1\n",
        "        # ipdb.set_trace()\n",
        "        # # using resize_ to just keep the first num_edges entries\n",
        "        # edge_index = edge_index.resize_(2, num_edges)\n",
        "        # edge_attr = edge_attr.resize_(num_edges, 1)\n",
        "\n",
        "        # randomly remove all of a nodes features\n",
        "        missing_feature_mask = get_missing_feature_mask(rate=0.4, n_nodes=n_node, n_features = self.config['N_HIST'], type=\"structural\")\n",
        "        \n",
        "\n",
        "        sequences = []\n",
        "        # T x F x N\n",
        "        for i in range(self.config['N_DAYS']):\n",
        "            for j in range(self.config['N_SLOT']):\n",
        "                # for each time point construct a different graph with data object\n",
        "                # Docs here: https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n",
        "                g = Data()\n",
        "                g.__num_nodes__ = n_node\n",
        "\n",
        "                g.edge_index = edge_index\n",
        "                g.edge_attr  = edge_attr\n",
        "\n",
        "                # (F,N) switched to (N,F)\n",
        "                sta = i * self.config['N_DAY_SLOT'] + j\n",
        "                end = sta + n_window\n",
        "                # [21, 228]\n",
        "\n",
        "                full_window = np.swapaxes(data[sta:end, :], 0, 1) # https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html\n",
        "                x = torch.FloatTensor(full_window[:, 0:self.config['N_HIST']])\n",
        "                x[~missing_feature_mask] = float(\"nan\") # filling missing position using nan\n",
        "                filled_feature = filling(\"feature_propagation\", edge_index, x, missing_feature_mask, num_iterations=40)\n",
        "\n",
        "                x = torch.where(missing_feature_mask, x, filled_feature)\n",
        "\n",
        "                g.x = x\n",
        "                g.y = torch.FloatTensor(full_window[:, self.config['N_HIST']::])\n",
        "                sequences += [g]\n",
        "\n",
        "        # Make the actual dataset\n",
        "        data, slices = self.collate(sequences)\n",
        "        torch.save((data, slices, n_node, mean, std_dev), self.processed_paths[0])\n",
        "\n",
        "def get_splits(dataset: TrafficDataset, n_slot, splits):\n",
        "    \"\"\"\n",
        "    Given the data, split it into random subsets of train, val, and test as given by splits\n",
        "    :param dataset: TrafficDataset object to split\n",
        "    :param n_slot: Number of possible sliding windows in a day\n",
        "    :param splits: (train, val, test) ratios\n",
        "    \"\"\"\n",
        "    split_train, split_val, _ = splits\n",
        "    i = n_slot*split_train\n",
        "    j = n_slot*split_val\n",
        "    train = dataset[:i]\n",
        "    val = dataset[i:i+j]\n",
        "    test = dataset[i+j:]\n",
        "\n",
        "    return train, val, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-GTzph59Kqe",
        "outputId": "72785b2d-64cf-4e00-cb4d-b1204ca9c06f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 12])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_missing_feature_mask(rate=0.3, n_nodes=20, n_features = 12, type=\"structural\").shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "#Build the Model\n",
        "\n",
        "Using PyG's built in layers, create a Spatio-Temporal Graph as presented in https://ieeexplore.ieee.org/document/8903252. \n",
        "\n",
        "Ths model is a Pytorch model containing an initialization function for setting up the model architecture, and a forward function for performing a forward pass of data through the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B7jt96q77EZF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "class ST_GAT(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-Temporal Graph Attention Network as presented in https://ieeexplore.ieee.org/document/8903252\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, n_nodes, heads=8, dropout=0.0):\n",
        "        \"\"\"\n",
        "        Initialize the ST-GAT model\n",
        "        :param in_channels Number of input channels\n",
        "        :param out_channels Number of output channels\n",
        "        :param n_nodes Number of nodes in the graph\n",
        "        :param heads Number of attention heads to use in graph\n",
        "        :param dropout Dropout probability on output of Graph Attention Network\n",
        "        \"\"\"\n",
        "        super(ST_GAT, self).__init__()\n",
        "        self.n_pred = out_channels\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.n_nodes = n_nodes\n",
        "\n",
        "        self.n_preds = 9\n",
        "        lstm1_hidden_size = 32\n",
        "        lstm2_hidden_size = 128\n",
        "\n",
        "        # single graph attentional layer with 8 attention heads\n",
        "        self.gat = GATConv(in_channels=in_channels, out_channels=in_channels,\n",
        "            heads=heads, dropout=0, concat=False)\n",
        "\n",
        "        # add two LSTM layers\n",
        "        self.lstm1 = torch.nn.LSTM(input_size=self.n_nodes, hidden_size=lstm1_hidden_size, num_layers=1)\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                torch.nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "        self.lstm2 = torch.nn.LSTM(input_size=lstm1_hidden_size, hidden_size=lstm2_hidden_size, num_layers=1)\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                torch.nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "\n",
        "        # fully-connected neural network\n",
        "        self.linear = torch.nn.Linear(lstm2_hidden_size, self.n_nodes*self.n_pred)\n",
        "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
        "\n",
        "    def forward(self, data, device):\n",
        "        \"\"\"\n",
        "        Forward pass of the ST-GAT model\n",
        "        :param data Data to make a pass on\n",
        "        :param device Device to operate on\n",
        "        \"\"\"\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # apply dropout\n",
        "        if device == 'cpu':\n",
        "            x = torch.FloatTensor(x)\n",
        "        else:\n",
        "            x = torch.cuda.FloatTensor(x)\n",
        "\n",
        "        # gat layer: output of gat: [11400, 12]\n",
        "        x = self.gat(x, edge_index)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        # RNN: 2 LSTM\n",
        "        # [batchsize*n_nodes, seq_length] -> [batch_size, n_nodes, seq_length]\n",
        "        batch_size = data.num_graphs\n",
        "        n_node = int(data.num_nodes/batch_size)\n",
        "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
        "        # for lstm: x should be (seq_length, batch_size, n_nodes)\n",
        "        # sequence length = 12, batch_size = 50, n_node = 228\n",
        "        x = torch.movedim(x, 2, 0)\n",
        "        # [12, 50, 228] -> [12, 50, 32]\n",
        "        x, _ = self.lstm1(x)\n",
        "        # [12, 50, 32] -> [12, 50, 128]\n",
        "        x, _ = self.lstm2(x)\n",
        "\n",
        "        # Output contains h_t for each timestep, only the last one has all input's accounted for\n",
        "        # [12, 50, 128] -> [50, 128]\n",
        "        x = torch.squeeze(x[-1, :, :])\n",
        "        # [50, 128] -> [50, 228*9]\n",
        "        x = self.linear(x)\n",
        "\n",
        "        # Now reshape into final output\n",
        "        s = x.shape\n",
        "        # [50, 228*9] -> [50, 228, 9]\n",
        "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
        "        # [50, 228, 9] ->  [11400, 9]\n",
        "        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W42pHHlz7GUv"
      },
      "source": [
        "##Create Train and Evaluation functions\n",
        "\n",
        "Create a train function which performs a forward and a backward pass using the model.\n",
        "\n",
        "Create an evaluation function which performs only a forward pass using the model.\n",
        "\n",
        "These functions will be used in various stages of overall model training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mcifitQO7uag"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval(model, device, dataloader, type=''):\n",
        "    \"\"\"\n",
        "    Evaluation function to evaluate model on data\n",
        "    :param model Model to evaluate\n",
        "    :param device Device to evaluate on\n",
        "    :param dataloader Data loader\n",
        "    :param type Name of evaluation type, e.g. Train/Val/Test\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    mae = 0\n",
        "    rmse = 0\n",
        "    mape = 0\n",
        "    n = 0\n",
        "\n",
        "    # Evaluate model on all data\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        batch = batch.to(device)\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                pred = model(batch, device)\n",
        "            truth = batch.y.view(pred.shape)\n",
        "            if i == 0:\n",
        "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
        "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
        "            truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
        "            pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
        "            y_pred[i, :pred.shape[0], :] = pred\n",
        "            y_truth[i, :pred.shape[0], :] = truth\n",
        "            rmse += RMSE(truth, pred)\n",
        "            mae += MAE(truth, pred)\n",
        "            mape += MAPE(truth, pred)\n",
        "            n += 1\n",
        "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
        "\n",
        "    print(f'{type}, MAE: {mae}, RMSE: {rmse}, MAPE: {mape}')\n",
        "\n",
        "    #get the average score for each metric in each batch\n",
        "    return rmse, mae, mape, y_pred, y_truth\n",
        "\n",
        "def train(model, device, dataloader, optimizer, loss_fn, epoch):\n",
        "    \"\"\"\n",
        "    Evaluation function to evaluate model on data\n",
        "    :param model Model to evaluate\n",
        "    :param device Device to evaluate on\n",
        "    :param dataloader Data loader\n",
        "    :param optimizer Optimizer to use\n",
        "    :param loss_fn Loss function\n",
        "    :param epoch Current epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = torch.squeeze(model(batch, device))\n",
        "        loss = loss_fn()(y_pred.float(), torch.squeeze(batch.y).float())\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tXJUu38HGo"
      },
      "source": [
        "In order to evaluation the performance of the model, we need to define some evaluation metrics.  \n",
        "\n",
        "*   The Z-score normalizes data using mean and std deviation.\n",
        "*   MAPE is mean average percentage error. \n",
        "*   RMSE is root mean square error.\n",
        "*   MAE is mean absolute error. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0CP54Sdb8HRC"
      },
      "outputs": [],
      "source": [
        "def z_score(x, mean, std):\n",
        "    \"\"\"\n",
        "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
        "    where z is the z-score, X is the value of the element,\n",
        "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
        "    :param x: torch array, input array to be normalized.\n",
        "    :param mean: float, the value of mean.\n",
        "    :param std: float, the value of standard deviation.\n",
        "    :return: torch array, z-score normalized array.\n",
        "    \"\"\"\n",
        "    return (x - mean) / std\n",
        "\n",
        "def un_z_score(x_normed, mean, std):\n",
        "    \"\"\"\n",
        "    Undo the Z-score calculation\n",
        "    :param x_normed: torch array, input array to be un-normalized.\n",
        "    :param mean: float, the value of mean.\n",
        "    :param std: float, the value of standard deviation.\n",
        "    \"\"\"\n",
        "    return x_normed * std  + mean\n",
        "\n",
        "\n",
        "def MAPE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean absolute percentage error, given as a % (e.g. 99 -> 99%)\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, MAPE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.abs((v_ - v)) /(v + 1e-15) * 100)\n",
        "\n",
        "\n",
        "def RMSE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean squared error.\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, RMSE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.sqrt(torch.mean((v_ - v) ** 2))\n",
        "\n",
        "\n",
        "def MAE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean absolute error.\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, MAE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.abs(v_ - v))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQmkAf1W7z2f"
      },
      "source": [
        "Now, let's put it all together. Let's use the `train` and `eval` functions along with the model and dataloadres to create a training function (`model_train`) and testing function (`model_test`).\n",
        "\n",
        "We also build in tensorboard support for logging of the training metrics over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iwQHMBp975LP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def model_train(train_dataloader, val_dataloader, config, device):\n",
        "    \"\"\"\n",
        "    Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
        "    :param train_dataloader Data loader of training dataset\n",
        "    :param val_dataloader Dataloader of val dataset\n",
        "    :param config configuration to use\n",
        "    :param device Device to evaluate on\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the model. Each datapoint in the graph is 228x12: N x F (N = # nodes, F = time window)\n",
        "    model = ST_GAT(in_channels=config['N_HIST'], out_channels=config['N_PRED'], n_nodes=config['N_NODE'], dropout=config['DROPOUT'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'], weight_decay=config['WEIGHT_DECAY'])\n",
        "    loss_fn = torch.nn.MSELoss\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n",
        "    for epoch in range(config['EPOCHS']):\n",
        "        loss = train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
        "        print(f\"Loss: {loss:.3f}\")\n",
        "        if epoch % 5 == 0:\n",
        "            train_mae, train_rmse, train_mape, _, _ = eval(model, device, train_dataloader, 'Train')\n",
        "            val_mae, val_rmse, val_mape, _, _ = eval(model, device, val_dataloader, 'Valid')\n",
        "            writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n",
        "            writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n",
        "            writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n",
        "            writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n",
        "            writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n",
        "            writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n",
        "\n",
        "    writer.flush()\n",
        "    # Save the model\n",
        "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
        "    torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss,\n",
        "            }, os.path.join(config[\"CHECKPOINT_DIR\"], f\"model_{timestr}.pt\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def model_test(model, test_dataloader, device, config):\n",
        "    \"\"\"\n",
        "    Test the ST-GAT model\n",
        "    :param test_dataloader Data loader of test dataset\n",
        "    :param device Device to evaluate on\n",
        "    \"\"\"\n",
        "    _, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUj42a8B_6wE"
      },
      "source": [
        "##Start training\n",
        "\n",
        "Now with all code in place, let's set up config, load our dataset, and start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3ssSNGGU0J"
      },
      "source": [
        "First, to watch your training over time, load the tensorboard extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbA6aPl0GH-F"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyZlmf8BGZx5"
      },
      "source": [
        "Now, create your dataloaders and start training!\n",
        "\n",
        "In our default configuration, we train for 60 epochs with a batch size of 50. You can view your training progress in the tensorboard above by clicking the \"refresh\" button to see new data. Training and validation performance are updated every 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFwnhhQJCEOO",
        "outputId": "f8cbe6b3-4797-443d-f094-6e9483ee1dde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\02_LA_case.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m distances \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./dataset/PeMSD7_W_228.csv\u001b[39m\u001b[39m'\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m W \u001b[39m=\u001b[39m distance_to_weight(distances, gat_version\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mUSE_GAT_WEIGHTS\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m dataset \u001b[39m=\u001b[39m TrafficDataset(config, W)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m d_train, d_val, d_test \u001b[39m=\u001b[39m get_splits(dataset, config[\u001b[39m'\u001b[39m\u001b[39mN_SLOT\u001b[39m\u001b[39m'\u001b[39m], (\u001b[39m34\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m))\n",
            "\u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\02_LA_case.ipynb Cell 28\u001b[0m in \u001b[0;36mTrafficDataset.__init__\u001b[1;34m(self, config, W, root, transform, pre_transform)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW \u001b[39m=\u001b[39m W\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# ipdb.set_trace()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform) \u001b[39m# would call __init__ of Class InMemoryDataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_node, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstd_dev \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:50\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m              transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m              pre_transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m              pre_filter: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 50\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:87\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:170\u001b[0m, in \u001b[0;36mDataset._process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m    169\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[1;32m--> 170\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[0;32m    172\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    173\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
            "\u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\02_LA_case.ipynb Cell 28\u001b[0m in \u001b[0;36mTrafficDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(full_window[:, \u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mN_HIST\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m x[\u001b[39m~\u001b[39mmissing_feature_mask] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnan\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# filling missing position using nan\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m filled_feature \u001b[39m=\u001b[39m filling(\u001b[39m\"\u001b[39m\u001b[39mfeature_propagation\u001b[39m\u001b[39m\"\u001b[39m, edge_index, x, missing_feature_mask, num_iterations\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(missing_feature_mask, x, filled_feature)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/02_LA_case.ipynb#X35sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m g\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m x\n",
            "File \u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\filling_strategies.py:55\u001b[0m, in \u001b[0;36mfilling\u001b[1;34m(filling_method, edge_index, X, feature_mask, num_iterations)\u001b[0m\n\u001b[0;32m     53\u001b[0m     X_reconstructed \u001b[39m=\u001b[39m neighborhood_mean_filling(edge_index, X, feature_mask)\n\u001b[0;32m     54\u001b[0m \u001b[39melif\u001b[39;00m filling_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfeature_propagation\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m     X_reconstructed \u001b[39m=\u001b[39m feature_propagation(edge_index, X, feature_mask, num_iterations)\n\u001b[0;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfilling_method\u001b[39m}\u001b[39;00m\u001b[39m method not implemented\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\filling_strategies.py:42\u001b[0m, in \u001b[0;36mfeature_propagation\u001b[1;34m(edge_index, X, feature_mask, num_iterations)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_propagation\u001b[39m(edge_index, X, feature_mask, num_iterations):\n\u001b[0;32m     40\u001b[0m     propagation_model \u001b[39m=\u001b[39m FeaturePropagation(num_iterations\u001b[39m=\u001b[39mnum_iterations)\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m propagation_model\u001b[39m.\u001b[39;49mpropagate(x\u001b[39m=\u001b[39;49mX, edge_index\u001b[39m=\u001b[39;49medge_index, mask\u001b[39m=\u001b[39;49mfeature_mask)\n",
            "File \u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\feature_propagation.py:31\u001b[0m, in \u001b[0;36mFeaturePropagation.propagate\u001b[1;34m(self, x, edge_index, mask)\u001b[0m\n\u001b[0;32m     29\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39mmm(adj, out)\n\u001b[0;32m     30\u001b[0m     \u001b[39m# Reset original known features\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     out[mask] \u001b[39m=\u001b[39m x[mask]\n\u001b[0;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Constant config to use throughout\n",
        "config = {\n",
        "    'BATCH_SIZE': 50,\n",
        "    'EPOCHS': 60,\n",
        "    'WEIGHT_DECAY': 5e-5,\n",
        "    'INITIAL_LR': 3e-4,\n",
        "    'CHECKPOINT_DIR': './runs',\n",
        "    'N_PRED': 9,\n",
        "    'N_HIST': 12,\n",
        "    'DROPOUT': 0.2,\n",
        "    # number of possible 5 minute measurements per day\n",
        "    'N_DAY_SLOT': 288,\n",
        "    # number of days worth of data in the dataset\n",
        "    'N_DAYS': 44,\n",
        "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
        "    'USE_GAT_WEIGHTS': True,\n",
        "    'N_NODE': 228,\n",
        "}\n",
        "# Number of possible windows in a day\n",
        "config['N_SLOT']= config['N_DAY_SLOT'] - (config['N_PRED']+config['N_HIST']) + 1\n",
        "\n",
        "# Load the weight and dataset dataset\n",
        "distances = pd.read_csv('./dataset/PeMSD7_W_228.csv', header=None).values\n",
        "W = distance_to_weight(distances, gat_version=config['USE_GAT_WEIGHTS'])\n",
        "dataset = TrafficDataset(config, W)\n",
        "\n",
        "# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\n",
        "d_train, d_val, d_test = get_splits(dataset, config['N_SLOT'], (34, 5, 5))\n",
        "train_dataloader = DataLoader(d_train, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
        "val_dataloader = DataLoader(d_val, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
        "test_dataloader = DataLoader(d_test, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "# Get gpu if you can\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "# Configure and train model\n",
        "config['N_NODE'] = dataset.n_node\n",
        "model = model_train(train_dataloader, val_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nm7Xd8CI3Js"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "Now that we have a trained model, we can test it on the test dataset and visualize its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "9-_urKxjI2gQ",
        "outputId": "3d01f4fb-8c5c-4546-ecb6-03ff40185698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test, MAE: 3.971902847290039, RMSE: 6.542290687561035, MAPE: 9.678857803344727\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_prediction(test_dataloader, y_pred, y_truth, node, config):\n",
        "    # Calculate the truth\n",
        "    s = y_truth.shape\n",
        "    y_truth = y_truth.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
        "    # just get the first prediction out for the nth node\n",
        "    y_truth = y_truth[:, :, node, 0]\n",
        "    # Flatten to get the predictions for entire test dataset\n",
        "    y_truth = torch.flatten(y_truth)\n",
        "    day0_truth = y_truth[:config['N_SLOT']]\n",
        "\n",
        "\n",
        "    # Calculate the predicted\n",
        "    s = y_pred.shape\n",
        "    y_pred = y_pred.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
        "    # just get the first prediction out for the nth node\n",
        "    y_pred = y_pred[:, :, node, 0]\n",
        "    # Flatten to get the predictions for entire test dataset\n",
        "    y_pred = torch.flatten(y_pred)\n",
        "    # Just grab the first day\n",
        "    day0_pred = y_pred[:config['N_SLOT']]\n",
        "    t = [t for t in range(0, config['N_SLOT']*5, 5)]\n",
        "    plt.plot(t, day0_pred, label='ST-GAT')\n",
        "    plt.plot(t, day0_truth, label='truth')\n",
        "    plt.xlabel('Time (minutes)')\n",
        "    plt.ylabel('Speed prediction')\n",
        "    plt.title('Predictions of traffic over time')\n",
        "    plt.legend()\n",
        "    plt.savefig('predicted_times.png')\n",
        "    plt.show()\n",
        "    \n",
        "_, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
        "plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COGjouriMrDf"
      },
      "source": [
        "## Rejoice\n",
        "\n",
        "We hope that you have found this colab informative and useful. Note that our final performance lags that published by the paper slightly, we believe this is due to small differences in training parameters and initializations that were not published with the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhpvVunSygml",
        "outputId": "60a32d21-19d6-4e5f-c5a6-bd03b95924d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/stgat_traffic_prediction\n"
          ]
        }
      ],
      "source": [
        "%cd stgat_traffic_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KKhjRJc0M4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqcaDZaB2aky"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3eb6ec63d31b2929ed0aa774d3f655ae373f333001909991ae66e743897a2db"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

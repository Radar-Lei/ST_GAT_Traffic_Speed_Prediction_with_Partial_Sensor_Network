{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS",
        "tags": []
      },
      "source": [
        "# ST-GAT Traffic Speed Prediction with Partial Sensor Network\n",
        "## Kowlong case study\n",
        "by Da Lei"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxG3DeP7HVLn"
      },
      "source": [
        "\n",
        "\n",
        "Steps: \n",
        "1.   Installation and Setup\n",
        "2.   Creating a dataloader\n",
        "3.   Building the Model\n",
        "4.   Creating train and evaluation functions\n",
        "5.   Train the model\n",
        "6.   Test the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation and setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "We recommend using a GPU for running our project.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OraOHb9w5-o_",
        "outputId": "24e09718-6b68-47f7-a7b9-8382d3932bd1",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu\n",
            "1.12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXJ0KgzeLikx",
        "outputId": "ba4510fa-9bbc-4d93-e2de-adf39218df9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 793 kB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 11.2 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq ipdb\n",
        "import ipdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x207Q4T_C_w7"
      },
      "source": [
        "Install PyTorch, PyG, and other necessary python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "4dd70fae-e687-4c60-e7cb-c9a382a3deb5"
      },
      "outputs": [],
      "source": [
        "# Install torch geometric\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7A5EQM6VEU"
      },
      "source": [
        "Mount google for output directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "217684ed-993e-48ce-b4c4-1190345c81af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Cloning into 'stgat_traffic_prediction'...\n",
            "remote: Enumerating objects: 693, done.\u001b[K\n",
            "remote: Total 693 (delta 0), reused 0 (delta 0), pack-reused 693\u001b[K\n",
            "Receiving objects: 100% (693/693), 22.98 MiB | 15.05 MiB/s, done.\n",
            "Resolving deltas: 100% (370/370), done.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd '/content/'\n",
        "!git clone https://github.com/jswang/stgat_traffic_prediction.git\n",
        "# %cd stgat_traffic_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWq7UtqHMOx5"
      },
      "source": [
        "#### cd afer delete utils folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBeDJoKk8J3s",
        "outputId": "7f91b443-4d1a-40b5-b8cb-1a47512dbdb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/stgat_traffic_prediction\n"
          ]
        }
      ],
      "source": [
        "%cd stgat_traffic_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7s-exY7Lik0",
        "outputId": "12a387ba-0ac2-49e5-de74-d2770d987998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata_loader\u001b[0m/  \u001b[01;34mdataset\u001b[0m/  \u001b[01;32mmain.py\u001b[0m*  \u001b[01;34mmodels\u001b[0m/  README.md  requirements.txt  \u001b[01;34mruns\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqOWp_S591MB"
      },
      "source": [
        "## Creating a Dataloader\n",
        "Now, we create a dataloader which will process data from `.csv` files into a PyTorch Geometric dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TEKy_v5EFPMt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from shutil import copyfile\n",
        "from filling_strategies import filling\n",
        "from utils import get_missing_feature_mask\n",
        "\n",
        "# ipdb.set_trace()\n",
        "\n",
        "def distance_to_weight(W, sigma2=0.01, epsilon=0.9, gat_version=False):\n",
        "    \"\"\"\"\n",
        "    Given distances between all nodes, convert into a weight matrix\n",
        "    :param W distances\n",
        "    :param sigma2 User configurable parameter to adjust sparsity of matrix\n",
        "    :param epsilon User configurable parameter to adjust sparsity of matrix\n",
        "    :param gat_version If true, use 0/1 weights with self loops. Otherwise, use float\n",
        "    \"\"\"\n",
        "    n = W.shape[0]\n",
        "    W = W / 10000.\n",
        "    W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
        "    # refer to Eq.10\n",
        "    W = np.exp(-W2 / sigma2) * (np.exp(-W2 / sigma2) >= epsilon) * W_mask\n",
        "\n",
        "    # If using the gat version of this, round to 0/1 and include self loops\n",
        "    if gat_version:\n",
        "      W[W>0] = 1\n",
        "      W += np.identity(n)\n",
        "\n",
        "    return W\n",
        "\n",
        "class TrafficDataset(InMemoryDataset):\n",
        "    \"\"\"\n",
        "    Dataset for Graph Neural Networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, W, root='', transform=None, pre_transform=None):\n",
        "        self.config = config\n",
        "        self.W = W\n",
        "        # ipdb.set_trace()\n",
        "        super().__init__(root, transform, pre_transform) # would call __init__ of Class InMemoryDataset\n",
        "        self.data, self.slices, self.n_node, self.mean, self.std_dev = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [os.path.join(self.raw_dir, 'kowlong_sensor_speed.csv')]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['./data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        copyfile('./dataset/kowlong_sensor_speed.csv', os.path.join(self.raw_dir, 'kowlong_sensor_speed.csv'))\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"\n",
        "        Process the raw datasets into saved .pt dataset for later use.\n",
        "        Note that any self.fields here wont exist if loading straight from the .pt file\n",
        "        \"\"\"\n",
        "        # Data Preprocessing and loading\n",
        "        # ipdb.set_trace()\n",
        "        data = pd.read_csv(self.raw_file_names[0], header=None).values\n",
        "        # data = np.nan_to_num(data, nan=-1)\n",
        "\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "        data = z_score(data, mean, std_dev)\n",
        "\n",
        "        n_feature, n_node_known = data.shape\n",
        "        n_node_unknown = self.config['N_NODE'] - n_node_known\n",
        "\n",
        "        data_unknown_init = np.zeros((n_feature, n_node_unknown))\n",
        "        data_unknown_init[:] = np.nan\n",
        "        data = np.concatenate((data,data_unknown_init), axis=1)\n",
        "\n",
        "        _, n_node = data.shape\n",
        "        n_window = self.config['N_PRED'] + self.config['N_HIST']\n",
        "\n",
        "        edge_index_ls_o = []\n",
        "        edge_index_ls_d = []\n",
        "        edge_attr = []\n",
        "        for i in range(n_node):\n",
        "          for j in range(n_node):\n",
        "            if self.W[i,j] != 0:\n",
        "              edge_index_ls_o.append(i)\n",
        "              edge_index_ls_d.append(j)\n",
        "              edge_attr.append(self.W[i,j])\n",
        "        edge_index = torch.tensor([edge_index_ls_o, edge_index_ls_d], dtype=torch.long)\n",
        "        edge_attr = torch.tensor(edge_attr).resize_(edge_index.shape[1], 1)\n",
        "\n",
        "        # another faster version for: adj matrix to edge_index\n",
        "        # adj_t = torch.tensor([[0,1,0,0],[1,0,0,0], [1,0,0,1], [0,0,1,0]])\n",
        "        # edge_index = adj_t.nonzero().t().contiguous()\n",
        "\n",
        "        # >>> tensor([[0, 1, 2, 2, 3],\n",
        "        #             [1, 0, 0, 3, 2]])\n",
        "\n",
        "        # # Below is the original version for generating edge_index and edge_attr \n",
        "        # # manipulate nxn matrix into 2xnum_edges\n",
        "        # edge_index = torch.zeros((2, n_node**2), dtype=torch.long)\n",
        "        # # create an edge_attr matrix with our weights  (num_edges x 1) --> our edge features are dim 1\n",
        "        # edge_attr = torch.zeros((n_node**2, 1))\n",
        "        # num_edges = 0\n",
        "        # for i in range(n_node):\n",
        "        #     for j in range(n_node):\n",
        "        #         if self.W[i, j] != 0.:\n",
        "        #             edge_index[0, num_edges] = i\n",
        "        #             edge_index[1, num_edges] = j\n",
        "        #             edge_attr[num_edges] = self.W[i, j]\n",
        "        #             num_edges += 1\n",
        "        # ipdb.set_trace()\n",
        "        # # using resize_ to just keep the first num_edges entries\n",
        "        # edge_index = edge_index.resize_(2, num_edges)\n",
        "        # edge_attr = edge_attr.resize_(num_edges, 1)\n",
        "\n",
        "        # randomly remove all of a nodes features\n",
        "        # missing_feature_mask = get_missing_feature_mask(rate=0.4, n_nodes=n_node, n_features = self.config['N_HIST'], type=\"structural\")\n",
        "        \n",
        "\n",
        "        sequences = []\n",
        "        # T x F x N\n",
        "        for i in range(self.config['N_DAYS']):\n",
        "            for j in range(self.config['N_SLOT']):\n",
        "                # for each time point construct a different graph with data object\n",
        "                # Docs here: https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n",
        "                g = Data()\n",
        "                g.__num_nodes__ = n_node\n",
        "\n",
        "                g.edge_index = edge_index\n",
        "                g.edge_attr  = edge_attr\n",
        "\n",
        "                # (F,N) switched to (N,F)\n",
        "                sta = i * self.config['N_DAY_SLOT'] + j\n",
        "                end = sta + n_window\n",
        "                # [21, 228]\n",
        "\n",
        "                full_window = np.swapaxes(data[sta:end, :], 0, 1) # https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html\n",
        "\n",
        "                x = torch.FloatTensor(full_window[:, 0:self.config['N_HIST']])\n",
        "                missing_feature_mask = torch.Tensor(np.isnan(x.numpy())).bool()\n",
        "                # x[missing_feature_mask] = float(\"nan\") # filling missing position using nan\n",
        "                filled_feature = filling(\"feature_propagation\", edge_index, x, ~missing_feature_mask, num_iterations=40)\n",
        "\n",
        "                x = torch.where(~missing_feature_mask, x, filled_feature)\n",
        "\n",
        "                g.x = x\n",
        "                g.y = torch.FloatTensor(full_window[:, self.config['N_HIST']::])\n",
        "                sequences += [g]\n",
        "\n",
        "        # Make the actual dataset\n",
        "        data, slices = self.collate(sequences)\n",
        "        torch.save((data, slices, n_node, mean, std_dev), self.processed_paths[0])\n",
        "\n",
        "def get_splits(dataset: TrafficDataset, n_slot, n_days, splits):\n",
        "    \"\"\"\n",
        "    Given the data, split it into random subsets of train, val, and test as given by splits\n",
        "    :param dataset: TrafficDataset object to split\n",
        "    :param n_slot: Number of possible sliding windows in a day\n",
        "    :param splits: (train, val, test) ratios\n",
        "    \"\"\"\n",
        "    split_train, split_val, _ = splits\n",
        "    i = int(n_slot*n_days*split_train)\n",
        "    j = int(n_slot*n_days*split_val)\n",
        "    train = dataset[:i]\n",
        "    val = dataset[i:i+j]\n",
        "    test = dataset[i+j:]\n",
        "\n",
        "    return train, val, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-GTzph59Kqe",
        "outputId": "72785b2d-64cf-4e00-cb4d-b1204ca9c06f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 12])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_missing_feature_mask(rate=0.3, n_nodes=20, n_features = 12, type=\"structural\").shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "#Build the Model\n",
        "\n",
        "Using PyG's built in layers, create a Spatio-Temporal Graph as presented in https://ieeexplore.ieee.org/document/8903252. \n",
        "\n",
        "Ths model is a Pytorch model containing an initialization function for setting up the model architecture, and a forward function for performing a forward pass of data through the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B7jt96q77EZF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "class ST_GAT(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-Temporal Graph Attention Network as presented in https://ieeexplore.ieee.org/document/8903252\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, n_nodes, heads=8, dropout=0.0):\n",
        "        \"\"\"\n",
        "        Initialize the ST-GAT model\n",
        "        :param in_channels Number of input channels\n",
        "        :param out_channels Number of output channels\n",
        "        :param n_nodes Number of nodes in the graph\n",
        "        :param heads Number of attention heads to use in graph\n",
        "        :param dropout Dropout probability on output of Graph Attention Network\n",
        "        \"\"\"\n",
        "        super(ST_GAT, self).__init__()\n",
        "        self.n_pred = out_channels\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.n_nodes = n_nodes\n",
        "\n",
        "        self.n_preds = 9\n",
        "        lstm1_hidden_size = 32\n",
        "        lstm2_hidden_size = 128\n",
        "\n",
        "        # single graph attentional layer with 8 attention heads\n",
        "        self.gat = GATConv(in_channels=in_channels, out_channels=in_channels,\n",
        "            heads=heads, dropout=0, concat=False)\n",
        "\n",
        "        # add two LSTM layers\n",
        "        self.lstm1 = torch.nn.LSTM(input_size=self.n_nodes, hidden_size=lstm1_hidden_size, num_layers=1)\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                torch.nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "        self.lstm2 = torch.nn.LSTM(input_size=lstm1_hidden_size, hidden_size=lstm2_hidden_size, num_layers=1)\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                torch.nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "\n",
        "        # fully-connected neural network\n",
        "        self.linear = torch.nn.Linear(lstm2_hidden_size, self.n_nodes*self.n_pred)\n",
        "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
        "\n",
        "    def forward(self, data, device):\n",
        "        \"\"\"\n",
        "        Forward pass of the ST-GAT model\n",
        "        :param data Data to make a pass on\n",
        "        :param device Device to operate on\n",
        "        \"\"\"\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # apply dropout\n",
        "        if device == 'cpu':\n",
        "            x = torch.FloatTensor(x)\n",
        "        else:\n",
        "            x = torch.cuda.FloatTensor(x)\n",
        "\n",
        "        # gat layer: output of gat: [11400, 12]\n",
        "        x = self.gat(x, edge_index)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        # RNN: 2 LSTM\n",
        "        # [batchsize*n_nodes, seq_length] -> [batch_size, n_nodes, seq_length]\n",
        "        batch_size = data.num_graphs\n",
        "        n_node = int(data.num_nodes/batch_size)\n",
        "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
        "        # for lstm: x should be (seq_length, batch_size, n_nodes)\n",
        "        # sequence length = 12, batch_size = 50, n_node = 228\n",
        "        x = torch.movedim(x, 2, 0)\n",
        "        # [12, 50, 228] -> [12, 50, 32]\n",
        "        x, _ = self.lstm1(x)\n",
        "        # [12, 50, 32] -> [12, 50, 128]\n",
        "        x, _ = self.lstm2(x)\n",
        "\n",
        "        # Output contains h_t for each timestep, only the last one has all input's accounted for\n",
        "        # [12, 50, 128] -> [50, 128]\n",
        "        x = torch.squeeze(x[-1, :, :])\n",
        "        # [50, 128] -> [50, 228*9]\n",
        "        x = self.linear(x)\n",
        "\n",
        "        # Now reshape into final output\n",
        "        s = x.shape\n",
        "        # [50, 228*9] -> [50, 228, 9]\n",
        "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
        "        # [50, 228, 9] ->  [11400, 9]\n",
        "        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W42pHHlz7GUv"
      },
      "source": [
        "##Create Train and Evaluation functions\n",
        "\n",
        "Create a train function which performs a forward and a backward pass using the model.\n",
        "\n",
        "Create an evaluation function which performs only a forward pass using the model.\n",
        "\n",
        "These functions will be used in various stages of overall model training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mcifitQO7uag"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval(model, device, dataloader, type=''):\n",
        "    \"\"\"\n",
        "    Evaluation function to evaluate model on data\n",
        "    :param model Model to evaluate\n",
        "    :param device Device to evaluate on\n",
        "    :param dataloader Data loader\n",
        "    :param type Name of evaluation type, e.g. Train/Val/Test\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    mae = 0\n",
        "    rmse = 0\n",
        "    mape = 0\n",
        "    n = 0\n",
        "\n",
        "    # Evaluate model on all data\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        batch = batch.to(device)\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                pred = model(batch, device)\n",
        "            truth = batch.y.view(pred.shape)\n",
        "            if i == 0:\n",
        "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
        "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
        "            truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
        "            pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
        "            y_pred[i, :pred.shape[0], :] = pred\n",
        "            y_truth[i, :pred.shape[0], :] = truth\n",
        "            rmse += RMSE(truth, pred)\n",
        "            mae += MAE(truth, pred)\n",
        "            mape += MAPE(truth, pred)\n",
        "            n += 1\n",
        "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
        "\n",
        "    print(f'{type}, MAE: {mae}, RMSE: {rmse}, MAPE: {mape}')\n",
        "\n",
        "    #get the average score for each metric in each batch\n",
        "    return rmse, mae, mape, y_pred, y_truth\n",
        "\n",
        "def train(model, device, dataloader, optimizer, loss_fn, epoch):\n",
        "    \"\"\"\n",
        "    Evaluation function to evaluate model on data\n",
        "    :param model Model to evaluate\n",
        "    :param device Device to evaluate on\n",
        "    :param dataloader Data loader\n",
        "    :param optimizer Optimizer to use\n",
        "    :param loss_fn Loss function\n",
        "    :param epoch Current epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = torch.squeeze(model(batch, device))\n",
        "        loss = loss_fn()(y_pred.float(), torch.squeeze(batch.y).float())\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tXJUu38HGo"
      },
      "source": [
        "In order to evaluation the performance of the model, we need to define some evaluation metrics.  \n",
        "\n",
        "*   The Z-score normalizes data using mean and std deviation.\n",
        "*   MAPE is mean average percentage error. \n",
        "*   RMSE is root mean square error.\n",
        "*   MAE is mean absolute error. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0CP54Sdb8HRC"
      },
      "outputs": [],
      "source": [
        "def z_score(x, mean, std):\n",
        "    \"\"\"\n",
        "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
        "    where z is the z-score, X is the value of the element,\n",
        "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
        "    :param x: torch array, input array to be normalized.\n",
        "    :param mean: float, the value of mean.\n",
        "    :param std: float, the value of standard deviation.\n",
        "    :return: torch array, z-score normalized array.\n",
        "    \"\"\"\n",
        "    return (x - mean) / std\n",
        "\n",
        "def un_z_score(x_normed, mean, std):\n",
        "    \"\"\"\n",
        "    Undo the Z-score calculation\n",
        "    :param x_normed: torch array, input array to be un-normalized.\n",
        "    :param mean: float, the value of mean.\n",
        "    :param std: float, the value of standard deviation.\n",
        "    \"\"\"\n",
        "    return x_normed * std  + mean\n",
        "\n",
        "\n",
        "def MAPE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean absolute percentage error, given as a % (e.g. 99 -> 99%)\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, MAPE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.abs((v_ - v)) /(v + 1e-15) * 100)\n",
        "\n",
        "\n",
        "def RMSE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean squared error.\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, RMSE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.sqrt(torch.mean((v_ - v) ** 2))\n",
        "\n",
        "\n",
        "def MAE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean absolute error.\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, MAE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.abs(v_ - v))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQmkAf1W7z2f"
      },
      "source": [
        "Now, let's put it all together. Let's use the `train` and `eval` functions along with the model and dataloadres to create a training function (`model_train`) and testing function (`model_test`).\n",
        "\n",
        "We also build in tensorboard support for logging of the training metrics over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iwQHMBp975LP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Make a tensorboard writer\n",
        "writer = SummaryWriter()\n",
        "\n",
        "def model_train(train_dataloader, val_dataloader, config, device):\n",
        "    \"\"\"\n",
        "    Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
        "    :param train_dataloader Data loader of training dataset\n",
        "    :param val_dataloader Dataloader of val dataset\n",
        "    :param config configuration to use\n",
        "    :param device Device to evaluate on\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the model. Each datapoint in the graph is 228x12: N x F (N = # nodes, F = time window)\n",
        "    model = ST_GAT(in_channels=config['N_HIST'], out_channels=config['N_PRED'], n_nodes=config['N_NODE'], dropout=config['DROPOUT'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'], weight_decay=config['WEIGHT_DECAY'])\n",
        "    loss_fn = torch.nn.MSELoss\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n",
        "    for epoch in range(config['EPOCHS']):\n",
        "        loss = train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
        "        print(f\"Loss: {loss:.3f}\")\n",
        "        if epoch % 5 == 0:\n",
        "            train_mae, train_rmse, train_mape, _, _ = eval(model, device, train_dataloader, 'Train')\n",
        "            val_mae, val_rmse, val_mape, _, _ = eval(model, device, val_dataloader, 'Valid')\n",
        "            writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n",
        "            writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n",
        "            writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n",
        "            writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n",
        "            writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n",
        "            writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n",
        "\n",
        "    # writer.flush()\n",
        "    # Save the model\n",
        "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
        "    torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss,\n",
        "            }, os.path.join(config[\"CHECKPOINT_DIR\"], f\"model_{timestr}.pt\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def model_test(model, test_dataloader, device, config):\n",
        "    \"\"\"\n",
        "    Test the ST-GAT model\n",
        "    :param test_dataloader Data loader of test dataset\n",
        "    :param device Device to evaluate on\n",
        "    \"\"\"\n",
        "    _, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUj42a8B_6wE"
      },
      "source": [
        "##Start training\n",
        "\n",
        "Now with all code in place, let's set up config, load our dataset, and start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3ssSNGGU0J"
      },
      "source": [
        "First, to watch your training over time, load the tensorboard extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbA6aPl0GH-F"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyZlmf8BGZx5"
      },
      "source": [
        "Now, create your dataloaders and start training!\n",
        "\n",
        "In our default configuration, we train for 60 epochs with a batch size of 50. You can view your training progress in the tensorboard above by clicking the \"refresh\" button to see new data. Training and validation performance are updated every 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFwnhhQJCEOO",
        "outputId": "ab3cbf1a-7b45-47a5-a822-5e35e3c8e5ff",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/22 [19:36<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_(Kowlong).ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Configure and train model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m config[\u001b[39m'\u001b[39m\u001b[39mN_NODE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mn_node\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m model \u001b[39m=\u001b[39m model_train(train_dataloader, val_dataloader, config, device)\n",
            "\u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_(Kowlong).ipynb Cell 29\u001b[0m in \u001b[0;36mmodel_train\u001b[1;34m(train_dataloader, val_dataloader, config, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# For every epoch, train the model on training dataset. Evaluate model on validation dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mEPOCHS\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "\u001b[1;32md:\\research_projects\\ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network\\01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_(Kowlong).ipynb Cell 29\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, dataloader, optimizer, loss_fn, epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(model(batch, device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn()(y_pred\u001b[39m.\u001b[39mfloat(), torch\u001b[39m.\u001b[39msqueeze(batch\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mLoss/train\u001b[39m\u001b[39m\"\u001b[39m, loss, epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/research_projects/ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network/01_ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network_%28Kowlong%29.ipynb#X40sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:387\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m workspace\n\u001b[0;32m    385\u001b[0m     scalar_value \u001b[39m=\u001b[39m workspace\u001b[39m.\u001b[39mFetchBlob(scalar_value)\n\u001b[1;32m--> 387\u001b[0m summary \u001b[39m=\u001b[39m scalar(\n\u001b[0;32m    388\u001b[0m     tag, scalar_value, new_style\u001b[39m=\u001b[39;49mnew_style, double_precision\u001b[39m=\u001b[39;49mdouble_precision\n\u001b[0;32m    389\u001b[0m )\n\u001b[0;32m    390\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_summary(summary, global_step, walltime)\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:279\u001b[0m, in \u001b[0;36mscalar\u001b[1;34m(name, scalar, collections, new_style, double_precision)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscalar\u001b[39m(name, scalar, collections\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, new_style\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, double_precision\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    264\u001b[0m     \u001b[39m\"\"\"Outputs a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m     scalar \u001b[39m=\u001b[39m make_np(scalar)\n\u001b[0;32m    280\u001b[0m     \u001b[39massert\u001b[39;00m scalar\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscalar should be 0D\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m     \u001b[39m# python float is double precision in numpy\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\tensorboard\\_convert_np.py:23\u001b[0m, in \u001b[0;36mmake_np\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([x])\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m _prepare_pytorch(x)\n\u001b[0;32m     24\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     25\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, but numpy array, torch tensor, or caffe2 blob name are expected.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     26\u001b[0m         \u001b[39mtype\u001b[39m(x)\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\great\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\tensorboard\\_convert_np.py:32\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_pytorch\u001b[39m(x):\n\u001b[1;32m---> 32\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Constant config to use throughout\n",
        "config = {\n",
        "    'BATCH_SIZE': 50,\n",
        "    'EPOCHS': 60,\n",
        "    'WEIGHT_DECAY': 5e-5,\n",
        "    'INITIAL_LR': 3e-4,\n",
        "    'CHECKPOINT_DIR': './runs',\n",
        "    'N_PRED': 9,\n",
        "    'N_HIST': 12,\n",
        "    'DROPOUT': 0.2,\n",
        "    # number of possible 5 minute measurements per day\n",
        "    'N_DAY_SLOT': 1189,\n",
        "    # number of days worth of data in the dataset\n",
        "    'N_DAYS': 1,\n",
        "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
        "    'USE_GAT_WEIGHTS': True,\n",
        "    'N_NODE': 849,\n",
        "}\n",
        "# Number of possible windows in a day\n",
        "config['N_SLOT']= config['N_DAY_SLOT'] - (config['N_PRED']+config['N_HIST']) + 1\n",
        "\n",
        "# Load the weight and dataset dataset\n",
        "distances = pd.read_csv('./dataset/kowlong_distance.csv',header=None).values\n",
        "W = distance_to_weight(distances, gat_version=config['USE_GAT_WEIGHTS'])\n",
        "dataset = TrafficDataset(config, W)\n",
        "# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\n",
        "d_train, d_val, d_test = get_splits(dataset, config['N_SLOT'], config['N_DAYS'], (0.9, 0.1, 0.1))\n",
        "train_dataloader = DataLoader(d_train, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
        "val_dataloader = DataLoader(d_val, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
        "test_dataloader = DataLoader(d_test, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "# Get gpu if you can\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "# Configure and train model\n",
        "config['N_NODE'] = dataset.n_node\n",
        "model = model_train(train_dataloader, val_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nm7Xd8CI3Js"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "Now that we have a trained model, we can test it on the test dataset and visualize its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "9-_urKxjI2gQ",
        "outputId": "6029c522-b264-440d-8c42-12574129bcee"
      },
      "outputs": [],
      "source": [
        "def plot_prediction(test_dataloader, y_pred, y_truth, node, config):\n",
        "    # Calculate the truth\n",
        "    s = y_truth.shape\n",
        "    y_truth = y_truth.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
        "    # just get the first prediction out for the nth node\n",
        "    y_truth = y_truth[:, :, node, 0]\n",
        "    # Flatten to get the predictions for entire test dataset\n",
        "    y_truth = torch.flatten(y_truth)\n",
        "    day0_truth = y_truth[:config['N_SLOT']]\n",
        "\n",
        "\n",
        "    # Calculate the predicted\n",
        "    s = y_pred.shape\n",
        "    y_pred = y_pred.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
        "    # just get the first prediction out for the nth node\n",
        "    y_pred = y_pred[:, :, node, 0]\n",
        "    # Flatten to get the predictions for entire test dataset\n",
        "    y_pred = torch.flatten(y_pred)\n",
        "    # Just grab the first day\n",
        "    day0_pred = y_pred[:config['N_SLOT']]\n",
        "    t = [t for t in range(0, config['N_SLOT']*5, 5)]\n",
        "    plt.plot(t, day0_pred, label='ST-GAT')\n",
        "    plt.plot(t, day0_truth, label='truth')\n",
        "    plt.xlabel('Time (minutes)')\n",
        "    plt.ylabel('Speed prediction')\n",
        "    plt.title('Predictions of traffic over time')\n",
        "    plt.legend()\n",
        "    plt.savefig('predicted_times.png')\n",
        "    plt.show()\n",
        "    \n",
        "_, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
        "plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COGjouriMrDf"
      },
      "source": [
        "## Rejoice\n",
        "\n",
        "We hope that you have found this colab informative and useful. Note that our final performance lags that published by the paper slightly, we believe this is due to small differences in training parameters and initializations that were not published with the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhpvVunSygml",
        "outputId": "60a32d21-19d6-4e5f-c5a6-bd03b95924d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/stgat_traffic_prediction\n"
          ]
        }
      ],
      "source": [
        "%cd stgat_traffic_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KKhjRJc0M4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqcaDZaB2aky"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('python-gis')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "30cc4c27f8e17a2992dc24ac03376ee4a12687a6c4423d61f00dba1ef4d15df4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

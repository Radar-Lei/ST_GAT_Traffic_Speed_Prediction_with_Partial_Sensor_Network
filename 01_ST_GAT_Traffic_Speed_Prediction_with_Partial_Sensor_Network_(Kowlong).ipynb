{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS",
    "tags": []
   },
   "source": [
    "# ST-GAT Traffic Speed Prediction with Partial Sensor Network\n",
    "## Kowlong case study\n",
    "by Da Lei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxG3DeP7HVLn"
   },
   "source": [
    "\n",
    "\n",
    "Steps: \n",
    "1.   Installation and Setup\n",
    "2.   Creating a dataloader\n",
    "3.   Building the Model\n",
    "4.   Creating train and evaluation functions\n",
    "5.   Train the model\n",
    "6.   Test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67gOQITlCNQi"
   },
   "source": [
    "## Installation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSaetj53YnT6"
   },
   "source": [
    "We recommend using a GPU for running our project.\n",
    "\n",
    "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OraOHb9w5-o_",
    "outputId": "d17aa75a-53f8-4756-f4b0-a2d0defc25cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x207Q4T_C_w7"
   },
   "source": [
    "Install PyTorch, PyG, and other necessary python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok7A5EQM6VEU"
   },
   "source": [
    "Mount google for output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eahqC9ei9cv-",
    "outputId": "ff81bb35-dcc6-4fa8-fb00-2610c791d0b3"
   },
   "outputs": [],
   "source": [
    "# %cd ST_GAT_Traffic_Speed_Prediction_with_Partial_Sensor_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7s-exY7Lik0",
    "outputId": "01bfd687-e254-4126-aaf4-2f781a1b2017"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqOWp_S591MB"
   },
   "source": [
    "## Creating a Dataloader\n",
    "Now, we create a dataloader which will process data from `.csv` files into a PyTorch Geometric dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEKy_v5EFPMt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from shutil import copyfile\n",
    "from filling_strategies import filling\n",
    "from utils import get_missing_feature_mask\n",
    "\n",
    "# ipdb.set_trace()\n",
    "\n",
    "def distance_to_weight(W, sigma2=0.01, epsilon=0.8, gat_version=False):\n",
    "    \"\"\"\"\n",
    "    Given distances between all nodes, convert into a weight matrix\n",
    "    :param W distances\n",
    "    :param sigma2 User configurable parameter to adjust sparsity of matrix\n",
    "    :param epsilon User configurable parameter to adjust sparsity of matrix\n",
    "    :param gat_version If true, use 0/1 weights with self loops. Otherwise, use float\n",
    "    \"\"\"\n",
    "    n = W.shape[0]\n",
    "    W = W / 10000.\n",
    "    W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
    "    # refer to Eq.10\n",
    "    W = np.exp(-W2 / sigma2) * (np.exp(-W2 / sigma2) >= epsilon) * W_mask\n",
    "\n",
    "    # If using the gat version of this, round to 0/1 and include self loops\n",
    "    if gat_version:\n",
    "      W[W>0] = 1\n",
    "      W += np.identity(n)\n",
    "\n",
    "    return W\n",
    "\n",
    "class TrafficDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    Dataset for Graph Neural Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, W, root='', transform=None, pre_transform=None):\n",
    "        self.config = config\n",
    "        self.W = W\n",
    "        # ipdb.set_trace()\n",
    "        super().__init__(root, transform, pre_transform) # would call __init__ of Class InMemoryDataset\n",
    "        self.data, self.slices, self.n_node, self.mean, self.std_dev = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [os.path.join(self.raw_dir, 'kowlong_sensor_speed.csv'), os.path.join(self.raw_dir, 'kowlong_nslot_ls.csv')]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['./data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        copyfile('./dataset/kowlong_sensor_speed.csv', os.path.join(self.raw_dir, 'kowlong_sensor_speed.csv'))\n",
    "        copyfile('./dataset/kowlong_nslot_ls.csv', os.path.join(self.raw_dir, 'kowlong_nslot_ls.csv'))\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Process the raw datasets into saved .pt dataset for later use.\n",
    "        Note that any self.fields here wont exist if loading straight from the .pt file\n",
    "        \"\"\"\n",
    "        # Data Preprocessing and loading\n",
    "        # ipdb.set_trace()\n",
    "        data = pd.read_csv(self.raw_file_names[0], header=None).values\n",
    "        # num of temporal graphs in each day\n",
    "        nslot_ls = np.squeeze(pd.read_csv(self.raw_file_names[1], header=None).values)\n",
    "\n",
    "        # data = np.nan_to_num(data, nan=-1)\n",
    "        \n",
    "        mean = np.nanmean(data)\n",
    "        std_dev = np.nanstd(data)\n",
    "        \n",
    "        data = z_score(data, mean, std_dev)\n",
    "\n",
    "        n_feature, n_node_known = data.shape\n",
    "        n_node_unknown = self.config['N_NODE'] - n_node_known\n",
    "\n",
    "        data_unknown_init = np.zeros((n_feature, n_node_unknown))\n",
    "        data_unknown_init[:] = np.nan\n",
    "        data = np.concatenate((data,data_unknown_init), axis=1)\n",
    "\n",
    "        _, n_node = data.shape\n",
    "        # length of each window\n",
    "        l_window = self.config['N_PRED'] + self.config['N_HIST']\n",
    "\n",
    "        edge_index_ls_o = []\n",
    "        edge_index_ls_d = []\n",
    "        edge_attr = []\n",
    "        for i in range(n_node):\n",
    "          for j in range(n_node):\n",
    "            if self.W[i,j] != 0:\n",
    "              edge_index_ls_o.append(i)\n",
    "              edge_index_ls_d.append(j)\n",
    "              edge_attr.append(self.W[i,j])\n",
    "        edge_index = torch.tensor([edge_index_ls_o, edge_index_ls_d], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_attr).resize_(edge_index.shape[1], 1)\n",
    "\n",
    "        # another faster version for: adj matrix to edge_index\n",
    "        # adj_t = torch.tensor([[0,1,0,0],[1,0,0,0], [1,0,0,1], [0,0,1,0]])\n",
    "        # edge_index = adj_t.nonzero().t().contiguous()\n",
    "\n",
    "        # >>> tensor([[0, 1, 2, 2, 3],\n",
    "        #             [1, 0, 0, 3, 2]])\n",
    "\n",
    "        # # Below is the original version for generating edge_index and edge_attr \n",
    "        # # manipulate nxn matrix into 2xnum_edges\n",
    "        # edge_index = torch.zeros((2, n_node**2), dtype=torch.long)\n",
    "        # # create an edge_attr matrix with our weights  (num_edges x 1) --> our edge features are dim 1\n",
    "        # edge_attr = torch.zeros((n_node**2, 1))\n",
    "        # num_edges = 0\n",
    "        # for i in range(n_node):\n",
    "        #     for j in range(n_node):\n",
    "        #         if self.W[i, j] != 0.:\n",
    "        #             edge_index[0, num_edges] = i\n",
    "        #             edge_index[1, num_edges] = j\n",
    "        #             edge_attr[num_edges] = self.W[i, j]\n",
    "        #             num_edges += 1\n",
    "        # ipdb.set_trace()\n",
    "        # # using resize_ to just keep the first num_edges entries\n",
    "        # edge_index = edge_index.resize_(2, num_edges)\n",
    "        # edge_attr = edge_attr.resize_(num_edges, 1)\n",
    "\n",
    "        # randomly remove all of a nodes features\n",
    "        # missing_feature_mask = get_missing_feature_mask(rate=0.4, n_nodes=n_node, n_features = self.config['N_HIST'], type=\"structural\")\n",
    "        \n",
    "        sequences = []\n",
    "        # num of possible window in each day\n",
    "        n_window_ls = [each - l_window + 1 for each in nslot_ls]\n",
    "        \n",
    "        # T x F x N\n",
    "        for i in range(self.config['N_DAYS']):\n",
    "            for j in range(n_window_ls[i]):\n",
    "                # for each time point construct a different graph with data object\n",
    "                # Docs here: https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n",
    "                g = Data()\n",
    "                g.__num_nodes__ = n_node\n",
    "\n",
    "                g.edge_index = edge_index\n",
    "                g.edge_attr  = edge_attr\n",
    "\n",
    "                # (F,N) switched to (N,F)\n",
    "                if i == 0: # if i == 0, start time step is j\n",
    "                  sta = j\n",
    "                  end = sta + l_window\n",
    "                else: # if not the 1st day, start point is\n",
    "                  sta = sum(nslot_ls[:i]) + j\n",
    "                  end = sta + l_window\n",
    "                # [21, 228]\n",
    "\n",
    "                full_window = np.swapaxes(data[sta:end, :], 0, 1) # https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html\n",
    "                full_window_tensor = torch.FloatTensor(full_window)\n",
    "                # for road intersections, there are structural missing data\n",
    "                # for traffic data from sensor, there are also possible partially missing values at some time points\n",
    "                # Thus, we need imputate all these NaN values, not only for the structural missing data\n",
    "                missing_feature_mask = torch.Tensor(np.isnan(full_window_tensor.numpy())).bool()\n",
    "                filled_feature = filling(\"feature_propagation\", edge_index, full_window_tensor, ~missing_feature_mask, num_iterations=40)\n",
    "                full_window_tensor = torch.where(~missing_feature_mask, full_window_tensor, filled_feature)\n",
    "\n",
    "                x = full_window_tensor[:, 0:self.config['N_HIST']]\n",
    "\n",
    "                # ipdb.set_trace()\n",
    "\n",
    "                # each row represents a node, we use the first column if the boolean\n",
    "                # matrix as the training mask, while some sensors (rows) could have\n",
    "                # missing values in the middle of its row\n",
    "                g.train_mask = ~missing_feature_mask[:, 0]\n",
    "\n",
    "                g.x = x\n",
    "                g.y = full_window_tensor[:, self.config['N_HIST']::]\n",
    "                sequences += [g]\n",
    "\n",
    "        # Make the actual dataset\n",
    "        data, slices = self.collate(sequences)\n",
    "        torch.save((data, slices, n_node, mean, std_dev), self.processed_paths[0])\n",
    "\n",
    "def get_splits(dataset: TrafficDataset, splits):\n",
    "    \"\"\"\n",
    "    Given the data, split it into random subsets of train, val, and test as given by splits\n",
    "    :param dataset: TrafficDataset object to split\n",
    "    :param n_slot: Number of possible sliding windows in a day\n",
    "    :param splits: (train, val, test) ratios\n",
    "    \"\"\"\n",
    "    n_slot = len(dataset)\n",
    "    split_train, split_val, _ = splits\n",
    "    i = round(int(n_slot*split_train), -1)\n",
    "    j = int(n_slot*split_val)\n",
    "    train = dataset[:i]\n",
    "    val = dataset[i:i+j]\n",
    "    test = dataset[i+j:]\n",
    "    \n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-GTzph59Kqe",
    "outputId": "72785b2d-64cf-4e00-cb4d-b1204ca9c06f"
   },
   "outputs": [],
   "source": [
    "get_missing_feature_mask(rate=0.3, n_nodes=20, n_features = 12, type=\"structural\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoXlf4MtYrbz"
   },
   "source": [
    "#Build the Model\n",
    "\n",
    "Using PyG's built in layers, create a Spatio-Temporal Graph as presented in https://ieeexplore.ieee.org/document/8903252. \n",
    "\n",
    "Ths model is a Pytorch model containing an initialization function for setting up the model architecture, and a forward function for performing a forward pass of data through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7jt96q77EZF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "class ST_GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-Temporal Graph Attention Network as presented in https://ieeexplore.ieee.org/document/8903252\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, n_nodes, heads=8, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the ST-GAT model\n",
    "        :param in_channels Number of input channels\n",
    "        :param out_channels Number of output channels\n",
    "        :param n_nodes Number of nodes in the graph\n",
    "        :param heads Number of attention heads to use in graph\n",
    "        :param dropout Dropout probability on output of Graph Attention Network\n",
    "        \"\"\"\n",
    "        super(ST_GAT, self).__init__()\n",
    "        self.n_pred = out_channels\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "        self.n_preds = 9\n",
    "        lstm1_hidden_size = 32\n",
    "        lstm2_hidden_size = 128\n",
    "\n",
    "        # single graph attentional layer with 8 attention heads\n",
    "        self.gat = GATConv(in_channels=in_channels, out_channels=in_channels,\n",
    "            heads=heads, dropout=0, concat=False)\n",
    "\n",
    "        # add two LSTM layers\n",
    "        self.lstm1 = torch.nn.LSTM(input_size=self.n_nodes, hidden_size=lstm1_hidden_size, num_layers=1)\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "        self.lstm2 = torch.nn.LSTM(input_size=lstm1_hidden_size, hidden_size=lstm2_hidden_size, num_layers=1)\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "        # fully-connected neural network\n",
    "        self.linear = torch.nn.Linear(lstm2_hidden_size, self.n_nodes*self.n_pred)\n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "        self.cnn = torch.nn.Conv1d(lstm2_hidden_size, self.n_nodes*self.n_pred, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, data, device):\n",
    "        \"\"\"\n",
    "        Forward pass of the ST-GAT model\n",
    "        :param data Data to make a pass on\n",
    "        :param device Device to operate on\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # apply dropout\n",
    "        if device == 'cpu':\n",
    "            x = torch.FloatTensor(x)\n",
    "        else:\n",
    "            x = torch.cuda.FloatTensor(x)\n",
    "\n",
    "        # gat layer: output of gat: [11400, 12]\n",
    "        x = self.gat(x, edge_index)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        # RNN: 2 LSTM\n",
    "        # [batchsize*n_nodes, seq_length] -> [batch_size, n_nodes, seq_length]\n",
    "        batch_size = data.num_graphs\n",
    "        n_node = int(data.num_nodes/batch_size)\n",
    "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
    "        # for lstm: x should be (seq_length, batch_size, n_nodes)\n",
    "        # sequence length = 12, batch_size = 50, n_node = 228\n",
    "        x = torch.movedim(x, 2, 0)\n",
    "        # [12, batch_size, n_node] -> [12, batch_size, 32]\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        # [12, batch_size, 32] -> [12, batch_size, 128]\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        # Output contains h_t for each timestep, only the last one has all input's accounted for\n",
    "        # [12, batch_size, 128] -> [batch_size, 128]\n",
    "        x = torch.squeeze(x[-1, :, :]).T\n",
    "        # [batch_size, 128] -> [batch_size, n_node*9]\n",
    "        x = self.cnn(x)\n",
    "        x = x.T\n",
    "        # x = self.linear(x)\n",
    "\n",
    "        # Now reshape into final output\n",
    "        s = x.shape\n",
    "        # [50, 228*9] -> [50, 228, 9]\n",
    "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
    "        # [50, 228, 9] ->  [11400, 9]\n",
    "        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W42pHHlz7GUv"
   },
   "source": [
    "##Create Train and Evaluation functions\n",
    "\n",
    "Create a train function which performs a forward and a backward pass using the model.\n",
    "\n",
    "Create an evaluation function which performs only a forward pass using the model.\n",
    "\n",
    "These functions will be used in various stages of overall model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcifitQO7uag"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, device, dataloader, type=''):\n",
    "    \"\"\"\n",
    "    Evaluation function to evaluate model on data\n",
    "    :param model Model to evaluate\n",
    "    :param device Device to evaluate on\n",
    "    :param dataloader Data loader\n",
    "    :param type Name of evaluation type, e.g. Train/Val/Test\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    mae = 0\n",
    "    rmse = 0\n",
    "    mape = 0\n",
    "    n = 0\n",
    "\n",
    "    # Evaluate model on all data\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch, device)\n",
    "            truth = batch.y.view(pred.shape)\n",
    "            if i == 0:\n",
    "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "            truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            y_pred[i, :pred.shape[0], :] = pred\n",
    "            y_truth[i, :pred.shape[0], :] = truth\n",
    "            \n",
    "            rmse += RMSE(truth[batch.train_mask], pred[batch.train_mask])\n",
    "            mae += MAE(truth[batch.train_mask], pred[batch.train_mask])\n",
    "            mape += MAPE(truth[batch.train_mask], pred[batch.train_mask])\n",
    "            n += 1\n",
    "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
    "\n",
    "    print(f'{type}, MAE: {mae}, RMSE: {rmse}, MAPE: {mape}')\n",
    "\n",
    "    #get the average score for each metric in each batch\n",
    "    return mae, rmse, mape, y_pred, y_truth\n",
    "\n",
    "def train(model, device, dataloader, optimizer, loss_fn, epoch):\n",
    "    \"\"\"\n",
    "    Evaluation function to evaluate model on data\n",
    "    :param model Model to evaluate\n",
    "    :param device Device to evaluate on\n",
    "    :param dataloader Data loader\n",
    "    :param optimizer Optimizer to use\n",
    "    :param loss_fn Loss function\n",
    "    :param epoch Current epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = torch.squeeze(model(batch, device))\n",
    "        loss = loss_fn()(y_pred[batch.train_mask].float(), torch.squeeze(batch.y[batch.train_mask]).float())\n",
    "\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        loss = loss + 0.00005 * l2_norm\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6tXJUu38HGo"
   },
   "source": [
    "In order to evaluation the performance of the model, we need to define some evaluation metrics.  \n",
    "\n",
    "*   The Z-score normalizes data using mean and std deviation.\n",
    "*   MAPE is mean average percentage error. \n",
    "*   RMSE is root mean square error.\n",
    "*   MAE is mean absolute error. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CP54Sdb8HRC"
   },
   "outputs": [],
   "source": [
    "def z_score(x, mean, std):\n",
    "    \"\"\"\n",
    "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
    "    where z is the z-score, X is the value of the element,\n",
    "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
    "    :param x: torch array, input array to be normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    :return: torch array, z-score normalized array.\n",
    "    \"\"\"\n",
    "    return (x - mean) / std\n",
    "\n",
    "def un_z_score(x_normed, mean, std):\n",
    "    \"\"\"\n",
    "    Undo the Z-score calculation\n",
    "    :param x_normed: torch array, input array to be un-normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    \"\"\"\n",
    "    return x_normed * std  + mean\n",
    "\n",
    "\n",
    "def MAPE(v, v_):\n",
    "    \"\"\"\n",
    "    Mean absolute percentage error, given as a % (e.g. 99 -> 99%)\n",
    "    :param v: torch array, ground truth.\n",
    "    :param v_: torch array, prediction.\n",
    "    :return: torch scalar, MAPE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.mean(torch.abs((v_ - v)) /(v + 1e-15) * 100)\n",
    "\n",
    "\n",
    "def RMSE(v, v_):\n",
    "    \"\"\"\n",
    "    Mean squared error.\n",
    "    :param v: torch array, ground truth.\n",
    "    :param v_: torch array, prediction.\n",
    "    :return: torch scalar, RMSE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.sqrt(torch.mean((v_ - v) ** 2))\n",
    "\n",
    "\n",
    "def MAE(v, v_):\n",
    "    \"\"\"\n",
    "    Mean absolute error.\n",
    "    :param v: torch array, ground truth.\n",
    "    :param v_: torch array, prediction.\n",
    "    :return: torch scalar, MAE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(v_ - v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQmkAf1W7z2f"
   },
   "source": [
    "Now, let's put it all together. Let's use the `train` and `eval` functions along with the model and dataloadres to create a training function (`model_train`) and testing function (`model_test`).\n",
    "\n",
    "We also build in tensorboard support for logging of the training metrics over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwQHMBp975LP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Make a tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def model_train(train_dataloader, val_dataloader, config, device):\n",
    "    \"\"\"\n",
    "    Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
    "    :param train_dataloader Data loader of training dataset\n",
    "    :param val_dataloader Dataloader of val dataset\n",
    "    :param config configuration to use\n",
    "    :param device Device to evaluate on\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the model. Each datapoint in the graph is 228x12: N x F (N = # nodes, F = time window)\n",
    "    model = ST_GAT(in_channels=config['N_HIST'], out_channels=config['N_PRED'], n_nodes=config['N_NODE'], dropout=config['DROPOUT'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'], weight_decay=config['WEIGHT_DECAY'])\n",
    "    loss_fn = torch.nn.MSELoss\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "        loss = train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
    "        print(f\"Loss: {loss:.3f}\")\n",
    "        if epoch % 5 == 0:\n",
    "            train_mae, train_rmse, train_mape, _, _ = eval(model, device, train_dataloader, 'Train')\n",
    "            val_mae, val_rmse, val_mape, _, _ = eval(model, device, val_dataloader, 'Valid')\n",
    "            writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n",
    "            writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n",
    "            writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n",
    "            writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n",
    "            writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n",
    "            writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n",
    "\n",
    "    writer.flush()\n",
    "    # Save the model\n",
    "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
    "    torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": loss,\n",
    "            }, os.path.join(config[\"CHECKPOINT_DIR\"], f\"model_{timestr}.pt\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_test(model, test_dataloader, device, config):\n",
    "    \"\"\"\n",
    "    Test the ST-GAT model\n",
    "    :param test_dataloader Data loader of test dataset\n",
    "    :param device Device to evaluate on\n",
    "    \"\"\"\n",
    "    _, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUj42a8B_6wE"
   },
   "source": [
    "##Start training\n",
    "\n",
    "Now with all code in place, let's set up config, load our dataset, and start training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC3ssSNGGU0J"
   },
   "source": [
    "First, to watch your training over time, load the tensorboard extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbA6aPl0GH-F"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyZlmf8BGZx5"
   },
   "source": [
    "Now, create your dataloaders and start training!\n",
    "\n",
    "In our default configuration, we train for 60 epochs with a batch size of 50. You can view your training progress in the tensorboard above by clicking the \"refresh\" button to see new data. Training and validation performance are updated every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "EFwnhhQJCEOO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Constant config to use throughout\n",
    "config = {\n",
    "    'BATCH_SIZE': 50,\n",
    "    'EPOCHS': 200,\n",
    "    'WEIGHT_DECAY': 5e-5,\n",
    "    'INITIAL_LR': 3e-4,\n",
    "    'CHECKPOINT_DIR': './runs',\n",
    "    'N_PRED': 9,\n",
    "    'N_HIST': 12,\n",
    "    'DROPOUT': 0.2,\n",
    "    # .csv record the number of time steps (graph screenshots) of each dat\n",
    "    'N_DAY_SLOT': './dataset/kowlong_nslot_ls.csv',\n",
    "    # number of days worth of data in the dataset\n",
    "    'N_DAYS': 31,\n",
    "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
    "    'USE_GAT_WEIGHTS': True,\n",
    "    'N_NODE': 532,\n",
    "}\n",
    "# Number of possible windows in a day\n",
    "# config['N_SLOT']= config['N_DAY_SLOT'] - (config['N_PRED']+config['N_HIST']) + 1\n",
    "\n",
    "# Load the weight and dataset dataset\n",
    "distances = pd.read_csv('./dataset/kowlong_distance.csv',header=None).values\n",
    "W = distance_to_weight(distances, gat_version=config['USE_GAT_WEIGHTS'])\n",
    "\n",
    "dataset = TrafficDataset(config, W)\n",
    "# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\n",
    "d_train, d_val, d_test = get_splits(dataset, (0.8, 0.1, 0.1))\n",
    "train_dataloader = DataLoader(d_train, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
    "val_dataloader = DataLoader(d_val, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
    "test_dataloader = DataLoader(d_test, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "# for each_batch in train_dataloader:\n",
    "#     each_batch\n",
    "#     break\n",
    "\n",
    "# Get gpu if you can\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Configure and train model\n",
    "config['N_NODE'] = dataset.n_node\n",
    "model = model_train(train_dataloader, val_dataloader, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Conv1d(16, 33, 1, stride=1)\n",
    "input = torch.randn(16, 50)\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nm7Xd8CI3Js"
   },
   "source": [
    "## Test the model\n",
    "\n",
    "Now that we have a trained model, we can test it on the test dataset and visualize its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Constant config to use throughout\n",
    "config = {\n",
    "    'BATCH_SIZE': 32,\n",
    "    'EPOCHS': 100,\n",
    "    'WEIGHT_DECAY': 5e-5,\n",
    "    'INITIAL_LR': 3e-4,\n",
    "    'CHECKPOINT_DIR': './runs',\n",
    "    'N_PRED': 9,\n",
    "    'N_HIST': 12,\n",
    "    'DROPOUT': 0.1,\n",
    "    # .csv record the number of time steps (graph screenshots) of each dat\n",
    "    'N_DAY_SLOT': './dataset/kowlong_nslot_ls.csv',\n",
    "    # number of days worth of data in the dataset\n",
    "    'N_DAYS': 31,\n",
    "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
    "    'USE_GAT_WEIGHTS': True,\n",
    "    'N_NODE': 532,\n",
    "}\n",
    "# Number of possible windows in a day\n",
    "# config['N_SLOT']= config['N_DAY_SLOT'] - (config['N_PRED']+config['N_HIST']) + 1\n",
    "\n",
    "# Load the weight and dataset dataset\n",
    "distances = pd.read_csv('./dataset/kowlong_distance.csv',header=None).values\n",
    "W = distance_to_weight(distances, gat_version=config['USE_GAT_WEIGHTS'])\n",
    "\n",
    "dataset = TrafficDataset(config, W)\n",
    "# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\n",
    "d_train, d_val, d_test = get_splits(dataset, (0.8, 0.1, 0.1))\n",
    "train_dataloader = DataLoader(d_train, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
    "val_dataloader = DataLoader(d_val, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
    "test_dataloader = DataLoader(d_test, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "# Get gpu if you can\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ST_GAT(in_channels=config['N_HIST'], out_channels=config['N_PRED'], n_nodes=config['N_NODE'], dropout=config['DROPOUT'])\n",
    "model.load_state_dict(torch.load('./runs/model_10-02-011929.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, y_pred, y_truth = eval(model, device, DataLoader(dataset[:3], batch_size=3, shuffle=False), 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-_urKxjI2gQ"
   },
   "outputs": [],
   "source": [
    "def plot_prediction(test_dataloader, y_pred, y_truth, node, config):\n",
    "    # Calculate the truth\n",
    "    s = y_truth.shape\n",
    "    y_truth = y_truth.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
    "    # just get the first prediction out for the nth node\n",
    "    y_truth = y_truth[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_truth = torch.flatten(y_truth)\n",
    "    day0_truth = y_truth[:config['N_SLOT']]\n",
    "\n",
    "\n",
    "    # Calculate the predicted\n",
    "    s = y_pred.shape\n",
    "    y_pred = y_pred.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
    "    # just get the first prediction out for the nth node\n",
    "    y_pred = y_pred[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_pred = torch.flatten(y_pred)\n",
    "    # Just grab the first day\n",
    "    day0_pred = y_pred[:config['N_SLOT']]\n",
    "    t = [t for t in range(0, config['N_SLOT']*5, 5)]\n",
    "    plt.plot(t, day0_pred, label='ST-GAT')\n",
    "    plt.plot(t, day0_truth, label='truth')\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Speed prediction')\n",
    "    plt.title('Predictions of traffic over time')\n",
    "    plt.legend()\n",
    "    plt.savefig('predicted_times.png')\n",
    "    plt.show()\n",
    "    \n",
    "_, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
    "plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(test_dataloader, y_pred, y_truth, node, config):\n",
    "    # Calculate the truth\n",
    "    s = y_truth.shape\n",
    "    y_truth = y_truth.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
    "    # just get the first prediction out for the nth node\n",
    "    y_truth = y_truth[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_truth = torch.flatten(y_truth)\n",
    "    day0_truth = y_truth[:config['N_SLOT']]\n",
    "\n",
    "\n",
    "    # Calculate the predicted\n",
    "    s = y_pred.shape\n",
    "    y_pred = y_pred.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
    "    # just get the first prediction out for the nth node\n",
    "    y_pred = y_pred[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_pred = torch.flatten(y_pred)\n",
    "    # Just grab the first day\n",
    "    day0_pred = y_pred[:config['N_SLOT']]\n",
    "    t = [t for t in range(0, config['N_SLOT']*1, 1)]\n",
    "    plt.plot(t, day0_pred, label='ST-GAT')\n",
    "    plt.plot(t, day0_truth, label='truth')\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Speed prediction')\n",
    "    plt.title('Predictions of traffic over time')\n",
    "    plt.legend()\n",
    "    plt.savefig('predicted_times.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return y_truth, y_pred\n",
    "\n",
    "nslot_ls = np.squeeze(pd.read_csv('./dataset/kowlong_nslot_ls.csv', header=None).values)\n",
    "_, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
    "config['N_SLOT'] = nslot_ls[0]\n",
    "\n",
    "y_truth_re, y_pred_re = plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COGjouriMrDf"
   },
   "source": [
    "## Rejoice\n",
    "\n",
    "We hope that you have found this colab informative and useful. Note that our final performance lags that published by the paper slightly, we believe this is due to small differences in training parameters and initializations that were not published with the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhpvVunSygml",
    "outputId": "60a32d21-19d6-4e5f-c5a6-bd03b95924d5"
   },
   "outputs": [],
   "source": [
    "%cd stgat_traffic_prediction"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2bd09eb641123562f45df3601a997d1d2cf0f88754338e8986ae05e2234ceb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
